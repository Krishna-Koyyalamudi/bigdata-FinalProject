# BigData Final Project
This repo is all about processing text using Databricks Community Edition and PySpark.

# Data Source
* The Project Gutenberg eBook of Pride and Prejudice, by Jane Austen.
* https://www.gutenberg.org/files/1342/1342-0.txt

# Tools & Languages
* Databricks Community Edition
* Python Programming Language
* PySpark
* Spark Processing Engine
* Seaborn
* Word Cloud

# Link to my published Databricks notebook
https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4950146981718460/105307159671369/5856159505929362/latest.html

# Commands
## Data Injection
* Python commands to import url library from the provided string url
```
import urllib.request
stringInURL = "https://www.gutenberg.org/files/1342/1342-0.txt"
urllib.request.urlretrieve(stringInURL, "/tmp/krish.txt")
```

* Move data from file in the file system to file in databricks file system
```
dbutils.fs.mv("file:/tmp/krish.txt", "dbfs:/data/PrideAndPrejudice.txt")
```

* Creating a Resilient distributed datasets
```
PrideAndPrejudice_RDD = sc.textFile("dbfs:/data/PrideAndPrejudice.txt")
```

## Data Cleaning
* split the data based on the spaces in between after converting to lower case
```
rawTextRDD = PrideAndPrejudice_RDD.flatMap(lambda line : line.lower().strip().split(" "))
```

* importing regular expression and executing a regex to eleiminate all the special Characters
```
import re
CleanRDD = rawTextRDD.map(lambda letter: re.sub(r'[^A-Za-z]', '', letter)
```

* Filtering stop words from the data
```
from pyspark.ml.feature import StopWordsRemover
remover = StopWordsRemover()
stopwords = remover.getStopWords()
WordsRDD = CleanRDD.filter(lambda Word: Word not in stopwords)
```

* Lambda expression to filter out unnecessary spaces
```
RemoveSpacesRDD = WordsRDD.filter(lambda x: x != "")
```

## Data Processing
* Creating key value pairs
```
KeyvaluePairsRDD = RemoveSpacesRDD.map(lambda word: (word,1))
```

* Reducing by key i.e., the frequency of words
```
wordCountRDD = KeyvaluePairsRDD.reduceByKey(lambda acc, value: acc + value)
```

* Creating a map of words and display in reverse order of word count
```
PrideAndPrejudiceResults = wordCountRDD.map(lambda x: (x[1], x[0])).sortByKey(False).take(10)
print(PrideAndPrejudiceResults)
```

## Charting
* I have used Pandas, MatPlotLib, and Seaborn to visualize the data we attained.
```
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

source = 'Pride and Prejudice, by Jane Austen'
title = 'Top Words Ten in ' + source
xlabel = 'Count'
ylabel = 'Words'

df = pd.DataFrame.from_records(PrideAndPrejudiceResults, columns =[xlabel, ylabel]) 
plt.figure(figsize=(10,5))
sns.barplot(xlabel, ylabel, data=df, palette="Spectral").set_title(title)
```
![WordCount](https://github.com/Krishna-Koyyalamudi/bigdata-FinalProject/blob/main/WordCount.PNG?raw=true)

# WordCloud
* To create a wordcloud, we will be needing nltk and wordcloud libraries.
* Before using these libraries we need to install and download nltk, wordcloud and popular to over come name not defined and stopwords errors.
```
pip install nltk
pip install wordcloud
nltk.download('popular')
```

```
import wordcloud
import nltk
import matplotlib.pyplot as plt

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud

class WordCloudGeneration:
    def preprocessing(self, data):
        # Converting all words to lowercase
        data = [item.lower() for item in data]
        # Load the stop_words of english
        stop_words = set(stopwords.words('english'))
        # Concatenate all the data with spaces.
        paragraph = ' '.join(data)
        # Using the inbuilt tokenizer, tokenize the paragraph
        word_tokens = word_tokenize(paragraph) 
        # Filter the words which are present in the stopwords list 
        preprocessed_data = ' '.join([word for word in word_tokens if not word in stop_words])
        print("\n Preprocessed Data: " ,preprocessed_data)
        return preprocessed_data

    def create_word_cloud(self, final_data):
        # Initiate WordCloud object with parameters width, height, maximum font size and background color
        wordcloud = WordCloud(width=1600, height=800, max_words=10, max_font_size=200, background_color="white").generate(final_data)
        # plt the image generated by the WordCloud class
        plt.figure(figsize=(12,10))
        plt.imshow(wordcloud)
        plt.axis("off")
        plt.show()

wordcloud_generator = WordCloudGeneration()
import urllib.request
url = "https://www.gutenberg.org/files/1342/1342-0.txt"
request = urllib.request.Request(url)
response = urllib.request.urlopen(request)
input_text = response.read().decode('utf-8')

input_text = input_text.split('.')
clean_data = wordcloud_generator.preprocessing(input_text)
wordcloud_generator.create_word_cloud(clean_data)
```

![WordCloud](https://github.com/Krishna-Koyyalamudi/bigdata-FinalProject/blob/main/WordCloud.PNG?raw=true)

# References
* https://github.com/alekhyajaddu/bigdata-finalproject
* https://www.section.io/engineering-education/word-cloud/
* https://seaborn.pydata.org/tutorial/color_palettes.html